import pandas as pd
import torch
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import requests

# 1. Load data (í•œê¸€ ì¸ì½”ë”© ê³ ë ¤ + ê²½ë¡œ ë°˜ì˜)
etf_df = pd.read_csv("data_4908_20250720.csv", encoding='cp949')

# 2. ê²€ìƒ‰ìš© ë¬¸ì¥ ìƒì„± (ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ ì¡°í•©: ì¢…ëª©ëª… + ê¸°ì´ˆì§€ìˆ˜ëª…)
etf_df["esg_text"] = etf_df["ì¢…ëª©ëª…"] + "ëŠ” " + etf_df["ê¸°ì´ˆì§€ìˆ˜_ì§€ìˆ˜ëª…"] + " ì§€ìˆ˜ë¥¼ ì¶”ì¢…í•©ë‹ˆë‹¤."

# 3. ì„ë² ë”© ëª¨ë¸ ë¡œë”©
embed_model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

# 4. ë¬¸ì¥ ì„ë² ë”© ë²¡í„°í™”
esg_docs = etf_df["esg_text"].tolist()
esg_embeddings = embed_model.encode(esg_docs)

# 5. ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ í•¨ìˆ˜
def retrieve_top_k(query, docs, embeddings, top_k=3):
    query_vec = embed_model.encode([query])
    scores = cosine_similarity(query_vec, embeddings)[0]
    top_indices = scores.argsort()[::-1][:top_k]
    return [docs[i] for i in top_indices]

# 6. HyperCLOVA X í˜¸ì¶œ í•¨ìˆ˜
def call_hyperclova_x(user_query, context_docs):
    url = "https://clovastudio.stream.ntruss.com/v3/chat-completions/HCX-005"
    headers = {
        "Authorization": "Bearer nv-50bf48a41b1848c09b1c77f84d75cd5bsZTj",  # ğŸ” ì—¬ê¸°ì— ë³¸ì¸ì˜ API í‚¤ ì…ë ¥
        "Content-Type": "application/json"
    }
    prompt = (
        f"[ì§ˆë¬¸]\n{user_query}\n\n"
        f"[ì°¸ê³  ë¬¸ì„œ]\n" + "\n".join(context_docs)
    )
    payload = {
        "messages": [
            {"role": "system", "content": "ê¸ˆìœµ ì „ë¬¸ê°€ë¡œ í–‰ë™í•˜ì„¸ìš”."},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.7,
        "topP": 0.8,
        "maxTokens": 1024,
        "stream": False
    }
    response = requests.post(url, headers=headers, json=payload)
    response.raise_for_status()
    return response.json()["result"]["message"]["content"]
